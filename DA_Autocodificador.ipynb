{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DA_Autoencoder.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oF--fivKQNTG",
        "outputId": "daa2f37e-559a-4cf6-e336-a9291569f0f1"
      },
      "source": [
        "!pip install pyod"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyod\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/50/94ac3c301b06e291ce52938e4a037b147cf01b40ff458dea5441ac42addf/pyod-0.8.7.tar.gz (101kB)\n",
            "\r\u001b[K     |███▎                            | 10kB 17.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20kB 22.5MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 30kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 51kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 61kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 71kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 81kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 92kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyod) (1.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pyod) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.7/dist-packages (from pyod) (1.19.5)\n",
            "Requirement already satisfied: numba>=0.35 in /usr/local/lib/python3.7/dist-packages (from pyod) (0.51.2)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.7/dist-packages (from pyod) (1.1.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from pyod) (1.4.1)\n",
            "Requirement already satisfied: scikit_learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from pyod) (0.22.2.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pyod) (1.15.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from pyod) (0.10.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.35->pyod) (54.1.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.35->pyod) (0.34.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25->pyod) (2018.9)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->pyod) (0.5.1)\n",
            "Building wheels for collected packages: pyod\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-0.8.7-cp37-none-any.whl size=115979 sha256=7acaf2b1fffaa88878374aefcd36b652ba59c11641a7f299e343734a23aa38fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/8a/c9/5fe3f32692ad445fe573cf5b953d7a0d55dc1f7c8e229ebda0\n",
            "Successfully built pyod\n",
            "Installing collected packages: pyod\n",
            "Successfully installed pyod-0.8.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0RktLNaQToB"
      },
      "source": [
        "import pandas as pd\n",
        "from pyod.models.auto_encoder import AutoEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGHS2gtWQ3hE"
      },
      "source": [
        "wine_df = pd.read_csv(\"/content/sample_data/wine.data\", header=None)\n",
        "wine_norm = wine_df.drop([0], axis=1)\n",
        "wine_norm = (wine_norm - wine_norm.min()) / (wine_norm.max() - wine_norm.min())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6poTeHsFRCyD",
        "outputId": "9c6aaa07-b9b6-492b-937d-30a57a3fa453"
      },
      "source": [
        "wine_norm.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(178, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKj02w7wRDKM",
        "outputId": "9647149e-4db6-4736-e4e3-16fa35373426"
      },
      "source": [
        "clf = AutoEncoder(hidden_neurons=[2], hidden_activation='sigmoid', epochs=300, contamination=0.07)\n",
        "clf.fit(wine_norm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 13)                182       \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 13)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 13)                182       \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 13)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 2)                 28        \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 2)                 0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 13)                39        \n",
            "=================================================================\n",
            "Total params: 431\n",
            "Trainable params: 431\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/300\n",
            "5/5 [==============================] - 1s 46ms/step - loss: 2.4230 - val_loss: 2.3491\n",
            "Epoch 2/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.4330 - val_loss: 2.3267\n",
            "Epoch 3/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.4516 - val_loss: 2.3045\n",
            "Epoch 4/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.3796 - val_loss: 2.2826\n",
            "Epoch 5/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.3893 - val_loss: 2.2613\n",
            "Epoch 6/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.3596 - val_loss: 2.2407\n",
            "Epoch 7/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.2965 - val_loss: 2.2205\n",
            "Epoch 8/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.3619 - val_loss: 2.2012\n",
            "Epoch 9/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.2759 - val_loss: 2.1820\n",
            "Epoch 10/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.2258 - val_loss: 2.1635\n",
            "Epoch 11/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.2450 - val_loss: 2.1458\n",
            "Epoch 12/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.1936 - val_loss: 2.1285\n",
            "Epoch 13/300\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.1669 - val_loss: 2.1117\n",
            "Epoch 14/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.2210 - val_loss: 2.0954\n",
            "Epoch 15/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.1513 - val_loss: 2.0795\n",
            "Epoch 16/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.1642 - val_loss: 2.0640\n",
            "Epoch 17/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.1779 - val_loss: 2.0490\n",
            "Epoch 18/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.1054 - val_loss: 2.0342\n",
            "Epoch 19/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.1369 - val_loss: 2.0201\n",
            "Epoch 20/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.0665 - val_loss: 2.0064\n",
            "Epoch 21/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.1476 - val_loss: 1.9931\n",
            "Epoch 22/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.0685 - val_loss: 1.9800\n",
            "Epoch 23/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.0062 - val_loss: 1.9672\n",
            "Epoch 24/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.0373 - val_loss: 1.9549\n",
            "Epoch 25/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.0369 - val_loss: 1.9429\n",
            "Epoch 26/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.0537 - val_loss: 1.9312\n",
            "Epoch 27/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.0063 - val_loss: 1.9197\n",
            "Epoch 28/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.0079 - val_loss: 1.9086\n",
            "Epoch 29/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.0021 - val_loss: 1.8977\n",
            "Epoch 30/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.9344 - val_loss: 1.8871\n",
            "Epoch 31/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.9705 - val_loss: 1.8767\n",
            "Epoch 32/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.9713 - val_loss: 1.8666\n",
            "Epoch 33/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9700 - val_loss: 1.8568\n",
            "Epoch 34/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.9199 - val_loss: 1.8472\n",
            "Epoch 35/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.9411 - val_loss: 1.8380\n",
            "Epoch 36/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.9031 - val_loss: 1.8289\n",
            "Epoch 37/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.9593 - val_loss: 1.8200\n",
            "Epoch 38/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.8956 - val_loss: 1.8113\n",
            "Epoch 39/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.8695 - val_loss: 1.8027\n",
            "Epoch 40/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.8662 - val_loss: 1.7942\n",
            "Epoch 41/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.8511 - val_loss: 1.7860\n",
            "Epoch 42/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.9055 - val_loss: 1.7782\n",
            "Epoch 43/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.8629 - val_loss: 1.7702\n",
            "Epoch 44/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.8401 - val_loss: 1.7624\n",
            "Epoch 45/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.8543 - val_loss: 1.7550\n",
            "Epoch 46/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.8237 - val_loss: 1.7475\n",
            "Epoch 47/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.8488 - val_loss: 1.7403\n",
            "Epoch 48/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.8055 - val_loss: 1.7330\n",
            "Epoch 49/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.8084 - val_loss: 1.7258\n",
            "Epoch 50/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.7370 - val_loss: 1.7189\n",
            "Epoch 51/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.7778 - val_loss: 1.7122\n",
            "Epoch 52/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.8018 - val_loss: 1.7054\n",
            "Epoch 53/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.7634 - val_loss: 1.6988\n",
            "Epoch 54/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.7536 - val_loss: 1.6925\n",
            "Epoch 55/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.7477 - val_loss: 1.6861\n",
            "Epoch 56/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.7915 - val_loss: 1.6799\n",
            "Epoch 57/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.7578 - val_loss: 1.6738\n",
            "Epoch 58/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.7969 - val_loss: 1.6679\n",
            "Epoch 59/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.7698 - val_loss: 1.6618\n",
            "Epoch 60/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.7948 - val_loss: 1.6559\n",
            "Epoch 61/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.7670 - val_loss: 1.6500\n",
            "Epoch 62/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.7576 - val_loss: 1.6444\n",
            "Epoch 63/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.7332 - val_loss: 1.6389\n",
            "Epoch 64/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.7158 - val_loss: 1.6332\n",
            "Epoch 65/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.7189 - val_loss: 1.6278\n",
            "Epoch 66/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.7374 - val_loss: 1.6224\n",
            "Epoch 67/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.6501 - val_loss: 1.6171\n",
            "Epoch 68/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.6987 - val_loss: 1.6118\n",
            "Epoch 69/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.6920 - val_loss: 1.6067\n",
            "Epoch 70/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.6979 - val_loss: 1.6015\n",
            "Epoch 71/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.6970 - val_loss: 1.5965\n",
            "Epoch 72/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.6374 - val_loss: 1.5913\n",
            "Epoch 73/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.6479 - val_loss: 1.5864\n",
            "Epoch 74/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.6392 - val_loss: 1.5815\n",
            "Epoch 75/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.6309 - val_loss: 1.5767\n",
            "Epoch 76/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.6434 - val_loss: 1.5719\n",
            "Epoch 77/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.6619 - val_loss: 1.5672\n",
            "Epoch 78/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.6123 - val_loss: 1.5626\n",
            "Epoch 79/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.7075 - val_loss: 1.5582\n",
            "Epoch 80/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.6183 - val_loss: 1.5535\n",
            "Epoch 81/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.6034 - val_loss: 1.5490\n",
            "Epoch 82/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.6234 - val_loss: 1.5446\n",
            "Epoch 83/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.5962 - val_loss: 1.5401\n",
            "Epoch 84/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.6272 - val_loss: 1.5357\n",
            "Epoch 85/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5789 - val_loss: 1.5316\n",
            "Epoch 86/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.6533 - val_loss: 1.5274\n",
            "Epoch 87/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.6118 - val_loss: 1.5232\n",
            "Epoch 88/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5668 - val_loss: 1.5189\n",
            "Epoch 89/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5966 - val_loss: 1.5148\n",
            "Epoch 90/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.6025 - val_loss: 1.5108\n",
            "Epoch 91/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5563 - val_loss: 1.5068\n",
            "Epoch 92/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.6055 - val_loss: 1.5028\n",
            "Epoch 93/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.5777 - val_loss: 1.4989\n",
            "Epoch 94/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.6070 - val_loss: 1.4950\n",
            "Epoch 95/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.5584 - val_loss: 1.4911\n",
            "Epoch 96/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5469 - val_loss: 1.4874\n",
            "Epoch 97/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.5375 - val_loss: 1.4834\n",
            "Epoch 98/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5278 - val_loss: 1.4798\n",
            "Epoch 99/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.5376 - val_loss: 1.4760\n",
            "Epoch 100/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4882 - val_loss: 1.4723\n",
            "Epoch 101/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5540 - val_loss: 1.4688\n",
            "Epoch 102/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5207 - val_loss: 1.4652\n",
            "Epoch 103/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.5325 - val_loss: 1.4617\n",
            "Epoch 104/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.5629 - val_loss: 1.4582\n",
            "Epoch 105/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5331 - val_loss: 1.4547\n",
            "Epoch 106/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.5163 - val_loss: 1.4513\n",
            "Epoch 107/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.5371 - val_loss: 1.4479\n",
            "Epoch 108/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.5416 - val_loss: 1.4445\n",
            "Epoch 109/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.5185 - val_loss: 1.4412\n",
            "Epoch 110/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.4825 - val_loss: 1.4380\n",
            "Epoch 111/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4562 - val_loss: 1.4347\n",
            "Epoch 112/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.4696 - val_loss: 1.4314\n",
            "Epoch 113/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4623 - val_loss: 1.4282\n",
            "Epoch 114/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4647 - val_loss: 1.4251\n",
            "Epoch 115/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.4982 - val_loss: 1.4220\n",
            "Epoch 116/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4944 - val_loss: 1.4190\n",
            "Epoch 117/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.4862 - val_loss: 1.4159\n",
            "Epoch 118/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4735 - val_loss: 1.4129\n",
            "Epoch 119/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4888 - val_loss: 1.4099\n",
            "Epoch 120/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5511 - val_loss: 1.4070\n",
            "Epoch 121/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4628 - val_loss: 1.4040\n",
            "Epoch 122/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4714 - val_loss: 1.4012\n",
            "Epoch 123/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4866 - val_loss: 1.3983\n",
            "Epoch 124/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4654 - val_loss: 1.3954\n",
            "Epoch 125/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.4623 - val_loss: 1.3925\n",
            "Epoch 126/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.4539 - val_loss: 1.3898\n",
            "Epoch 127/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4749 - val_loss: 1.3871\n",
            "Epoch 128/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4063 - val_loss: 1.3844\n",
            "Epoch 129/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.4494 - val_loss: 1.3816\n",
            "Epoch 130/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.4736 - val_loss: 1.3790\n",
            "Epoch 131/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4645 - val_loss: 1.3764\n",
            "Epoch 132/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4197 - val_loss: 1.3736\n",
            "Epoch 133/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4206 - val_loss: 1.3710\n",
            "Epoch 134/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4600 - val_loss: 1.3684\n",
            "Epoch 135/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4565 - val_loss: 1.3659\n",
            "Epoch 136/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3888 - val_loss: 1.3634\n",
            "Epoch 137/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4119 - val_loss: 1.3609\n",
            "Epoch 138/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4225 - val_loss: 1.3585\n",
            "Epoch 139/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4276 - val_loss: 1.3561\n",
            "Epoch 140/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4083 - val_loss: 1.3536\n",
            "Epoch 141/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4299 - val_loss: 1.3512\n",
            "Epoch 142/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.4021 - val_loss: 1.3488\n",
            "Epoch 143/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4180 - val_loss: 1.3464\n",
            "Epoch 144/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3823 - val_loss: 1.3442\n",
            "Epoch 145/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4118 - val_loss: 1.3419\n",
            "Epoch 146/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.4132 - val_loss: 1.3396\n",
            "Epoch 147/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.3773 - val_loss: 1.3373\n",
            "Epoch 148/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.3711 - val_loss: 1.3351\n",
            "Epoch 149/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.3905 - val_loss: 1.3329\n",
            "Epoch 150/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.3554 - val_loss: 1.3307\n",
            "Epoch 151/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.4106 - val_loss: 1.3285\n",
            "Epoch 152/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4050 - val_loss: 1.3265\n",
            "Epoch 153/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4107 - val_loss: 1.3243\n",
            "Epoch 154/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3702 - val_loss: 1.3222\n",
            "Epoch 155/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.3962 - val_loss: 1.3202\n",
            "Epoch 156/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3937 - val_loss: 1.3182\n",
            "Epoch 157/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.3611 - val_loss: 1.3161\n",
            "Epoch 158/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3765 - val_loss: 1.3140\n",
            "Epoch 159/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.3627 - val_loss: 1.3121\n",
            "Epoch 160/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.3550 - val_loss: 1.3102\n",
            "Epoch 161/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.3772 - val_loss: 1.3082\n",
            "Epoch 162/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.3264 - val_loss: 1.3062\n",
            "Epoch 163/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3430 - val_loss: 1.3044\n",
            "Epoch 164/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4032 - val_loss: 1.3025\n",
            "Epoch 165/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.3990 - val_loss: 1.3006\n",
            "Epoch 166/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.3256 - val_loss: 1.2988\n",
            "Epoch 167/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3569 - val_loss: 1.2969\n",
            "Epoch 168/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3417 - val_loss: 1.2950\n",
            "Epoch 169/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.3581 - val_loss: 1.2932\n",
            "Epoch 170/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3303 - val_loss: 1.2914\n",
            "Epoch 171/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.3327 - val_loss: 1.2896\n",
            "Epoch 172/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.3502 - val_loss: 1.2880\n",
            "Epoch 173/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.3218 - val_loss: 1.2863\n",
            "Epoch 174/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.3587 - val_loss: 1.2845\n",
            "Epoch 175/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3171 - val_loss: 1.2829\n",
            "Epoch 176/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3253 - val_loss: 1.2813\n",
            "Epoch 177/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.2770 - val_loss: 1.2796\n",
            "Epoch 178/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3401 - val_loss: 1.2779\n",
            "Epoch 179/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2923 - val_loss: 1.2763\n",
            "Epoch 180/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3132 - val_loss: 1.2747\n",
            "Epoch 181/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.3074 - val_loss: 1.2730\n",
            "Epoch 182/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3514 - val_loss: 1.2715\n",
            "Epoch 183/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.3191 - val_loss: 1.2699\n",
            "Epoch 184/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.2983 - val_loss: 1.2684\n",
            "Epoch 185/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3264 - val_loss: 1.2669\n",
            "Epoch 186/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2817 - val_loss: 1.2653\n",
            "Epoch 187/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.3085 - val_loss: 1.2639\n",
            "Epoch 188/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3163 - val_loss: 1.2624\n",
            "Epoch 189/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3459 - val_loss: 1.2609\n",
            "Epoch 190/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.3123 - val_loss: 1.2595\n",
            "Epoch 191/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.3215 - val_loss: 1.2581\n",
            "Epoch 192/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.3243 - val_loss: 1.2566\n",
            "Epoch 193/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.2760 - val_loss: 1.2552\n",
            "Epoch 194/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.3252 - val_loss: 1.2538\n",
            "Epoch 195/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.3189 - val_loss: 1.2524\n",
            "Epoch 196/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3285 - val_loss: 1.2510\n",
            "Epoch 197/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2631 - val_loss: 1.2496\n",
            "Epoch 198/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2873 - val_loss: 1.2482\n",
            "Epoch 199/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2675 - val_loss: 1.2469\n",
            "Epoch 200/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.2669 - val_loss: 1.2456\n",
            "Epoch 201/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2937 - val_loss: 1.2443\n",
            "Epoch 202/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3069 - val_loss: 1.2430\n",
            "Epoch 203/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2898 - val_loss: 1.2417\n",
            "Epoch 204/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2743 - val_loss: 1.2404\n",
            "Epoch 205/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2657 - val_loss: 1.2390\n",
            "Epoch 206/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.3157 - val_loss: 1.2378\n",
            "Epoch 207/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.3168 - val_loss: 1.2366\n",
            "Epoch 208/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3193 - val_loss: 1.2354\n",
            "Epoch 209/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.3174 - val_loss: 1.2341\n",
            "Epoch 210/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.2696 - val_loss: 1.2328\n",
            "Epoch 211/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2901 - val_loss: 1.2316\n",
            "Epoch 212/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2826 - val_loss: 1.2304\n",
            "Epoch 213/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2774 - val_loss: 1.2292\n",
            "Epoch 214/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2308 - val_loss: 1.2280\n",
            "Epoch 215/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.2589 - val_loss: 1.2269\n",
            "Epoch 216/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3068 - val_loss: 1.2258\n",
            "Epoch 217/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2575 - val_loss: 1.2246\n",
            "Epoch 218/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.2587 - val_loss: 1.2234\n",
            "Epoch 219/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.2515 - val_loss: 1.2223\n",
            "Epoch 220/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.2785 - val_loss: 1.2212\n",
            "Epoch 221/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.2348 - val_loss: 1.2200\n",
            "Epoch 222/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2952 - val_loss: 1.2189\n",
            "Epoch 223/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2880 - val_loss: 1.2179\n",
            "Epoch 224/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2246 - val_loss: 1.2167\n",
            "Epoch 225/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2635 - val_loss: 1.2157\n",
            "Epoch 226/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2671 - val_loss: 1.2146\n",
            "Epoch 227/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.2717 - val_loss: 1.2135\n",
            "Epoch 228/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.2725 - val_loss: 1.2126\n",
            "Epoch 229/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2970 - val_loss: 1.2116\n",
            "Epoch 230/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2570 - val_loss: 1.2105\n",
            "Epoch 231/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2970 - val_loss: 1.2095\n",
            "Epoch 232/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2520 - val_loss: 1.2085\n",
            "Epoch 233/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2642 - val_loss: 1.2074\n",
            "Epoch 234/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2570 - val_loss: 1.2064\n",
            "Epoch 235/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2768 - val_loss: 1.2054\n",
            "Epoch 236/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2406 - val_loss: 1.2044\n",
            "Epoch 237/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2067 - val_loss: 1.2034\n",
            "Epoch 238/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2672 - val_loss: 1.2025\n",
            "Epoch 239/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2574 - val_loss: 1.2015\n",
            "Epoch 240/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.2407 - val_loss: 1.2006\n",
            "Epoch 241/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2913 - val_loss: 1.1996\n",
            "Epoch 242/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2805 - val_loss: 1.1987\n",
            "Epoch 243/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2042 - val_loss: 1.1977\n",
            "Epoch 244/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2182 - val_loss: 1.1968\n",
            "Epoch 245/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2626 - val_loss: 1.1958\n",
            "Epoch 246/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2134 - val_loss: 1.1949\n",
            "Epoch 247/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.2255 - val_loss: 1.1940\n",
            "Epoch 248/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2323 - val_loss: 1.1931\n",
            "Epoch 249/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.2239 - val_loss: 1.1922\n",
            "Epoch 250/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.2579 - val_loss: 1.1913\n",
            "Epoch 251/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.1908 - val_loss: 1.1904\n",
            "Epoch 252/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2485 - val_loss: 1.1896\n",
            "Epoch 253/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2084 - val_loss: 1.1888\n",
            "Epoch 254/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2312 - val_loss: 1.1879\n",
            "Epoch 255/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.2447 - val_loss: 1.1870\n",
            "Epoch 256/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.1927 - val_loss: 1.1861\n",
            "Epoch 257/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2373 - val_loss: 1.1853\n",
            "Epoch 258/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2020 - val_loss: 1.1845\n",
            "Epoch 259/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.2225 - val_loss: 1.1836\n",
            "Epoch 260/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2304 - val_loss: 1.1827\n",
            "Epoch 261/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2299 - val_loss: 1.1819\n",
            "Epoch 262/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2241 - val_loss: 1.1810\n",
            "Epoch 263/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2252 - val_loss: 1.1803\n",
            "Epoch 264/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2282 - val_loss: 1.1795\n",
            "Epoch 265/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.1962 - val_loss: 1.1786\n",
            "Epoch 266/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.2556 - val_loss: 1.1778\n",
            "Epoch 267/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.2517 - val_loss: 1.1770\n",
            "Epoch 268/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.2005 - val_loss: 1.1762\n",
            "Epoch 269/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2033 - val_loss: 1.1754\n",
            "Epoch 270/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.2182 - val_loss: 1.1747\n",
            "Epoch 271/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.2024 - val_loss: 1.1739\n",
            "Epoch 272/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2209 - val_loss: 1.1731\n",
            "Epoch 273/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.1972 - val_loss: 1.1724\n",
            "Epoch 274/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.1847 - val_loss: 1.1716\n",
            "Epoch 275/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.2045 - val_loss: 1.1709\n",
            "Epoch 276/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.2193 - val_loss: 1.1701\n",
            "Epoch 277/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.2388 - val_loss: 1.1694\n",
            "Epoch 278/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2218 - val_loss: 1.1687\n",
            "Epoch 279/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2093 - val_loss: 1.1680\n",
            "Epoch 280/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2094 - val_loss: 1.1673\n",
            "Epoch 281/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.1697 - val_loss: 1.1665\n",
            "Epoch 282/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2322 - val_loss: 1.1658\n",
            "Epoch 283/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.1580 - val_loss: 1.1650\n",
            "Epoch 284/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2213 - val_loss: 1.1643\n",
            "Epoch 285/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.1648 - val_loss: 1.1636\n",
            "Epoch 286/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2017 - val_loss: 1.1629\n",
            "Epoch 287/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.1757 - val_loss: 1.1622\n",
            "Epoch 288/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.1580 - val_loss: 1.1615\n",
            "Epoch 289/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2055 - val_loss: 1.1608\n",
            "Epoch 290/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.1990 - val_loss: 1.1602\n",
            "Epoch 291/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.2126 - val_loss: 1.1595\n",
            "Epoch 292/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.1896 - val_loss: 1.1589\n",
            "Epoch 293/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.1510 - val_loss: 1.1582\n",
            "Epoch 294/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.1586 - val_loss: 1.1575\n",
            "Epoch 295/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2088 - val_loss: 1.1568\n",
            "Epoch 296/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.1878 - val_loss: 1.1562\n",
            "Epoch 297/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.1777 - val_loss: 1.1556\n",
            "Epoch 298/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.1970 - val_loss: 1.1549\n",
            "Epoch 299/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.2216 - val_loss: 1.1542\n",
            "Epoch 300/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.1825 - val_loss: 1.1536\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AutoEncoder(batch_size=32, contamination=0.07, dropout_rate=0.2, epochs=300,\n",
              "      hidden_activation='sigmoid', hidden_neurons=[2], l2_regularizer=0.1,\n",
              "      loss=<function mean_squared_error at 0x7f01b8ccc440>,\n",
              "      optimizer='adam', output_activation='sigmoid', preprocessing=True,\n",
              "      random_state=None, validation_size=0.1, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZe9MWrdRNb0",
        "outputId": "304ed60b-56fd-4ee8-8983-9e59150ad0f0"
      },
      "source": [
        "clf.predict(wine_norm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tz7vMgX6yD70"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}